{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas padrão (nenhuma neste caso)\n",
    "\n",
    "# Importar bibliotecas de terceiros\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importar pacotes específicos de bibliotecas ou funções\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   id_cliente             15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12427 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  renda                  15000 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Carregar base de dados\n",
    "renda_raw = pd.read_csv('previsao_de_renda.csv')\n",
    "renda_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12427 entries, 0 to 14999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             12427 non-null  int64  \n",
      " 1   data_ref               12427 non-null  object \n",
      " 2   id_cliente             12427 non-null  int64  \n",
      " 3   sexo                   12427 non-null  object \n",
      " 4   posse_de_veiculo       12427 non-null  bool   \n",
      " 5   posse_de_imovel        12427 non-null  bool   \n",
      " 6   qtd_filhos             12427 non-null  int64  \n",
      " 7   tipo_renda             12427 non-null  object \n",
      " 8   educacao               12427 non-null  object \n",
      " 9   estado_civil           12427 non-null  object \n",
      " 10  tipo_residencia        12427 non-null  object \n",
      " 11  idade                  12427 non-null  int64  \n",
      " 12  tempo_emprego          12427 non-null  float64\n",
      " 13  qt_pessoas_residencia  12427 non-null  float64\n",
      " 14  renda                  12427 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(4), object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Data Wrangling - Cleaning\n",
    "# Remover dados faltantes\n",
    "renda_raw = renda_raw.dropna()\n",
    "renda_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12427 entries, 0 to 14999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   sexo                   12427 non-null  object \n",
      " 1   posse_de_veiculo       12427 non-null  bool   \n",
      " 2   posse_de_imovel        12427 non-null  bool   \n",
      " 3   qtd_filhos             12427 non-null  int64  \n",
      " 4   tipo_renda             12427 non-null  object \n",
      " 5   educacao               12427 non-null  object \n",
      " 6   estado_civil           12427 non-null  object \n",
      " 7   tipo_residencia        12427 non-null  object \n",
      " 8   idade                  12427 non-null  int64  \n",
      " 9   tempo_emprego          12427 non-null  float64\n",
      " 10  qt_pessoas_residencia  12427 non-null  float64\n",
      " 11  renda                  12427 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(2), object(5)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Data Wrangling - Cleaning\n",
    "# Remover colunas desnecessárias\n",
    "renda = renda_raw.drop(['Unnamed: 0', 'data_ref', 'id_cliente'], axis=1)\n",
    "renda.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 - Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "# Separação dos dados em base de treino e base de teste\n",
    "y = renda['renda']\n",
    "X = pd.get_dummies(renda.drop(columns='renda'), drop_first=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
      "[0.16131259213638294, 0.16131740034474795, 0.16133379955753802, 0.16134820064183863, 0.1612657458426634, 0.16083317587216095]\n"
     ]
    }
   ],
   "source": [
    "# 02 - Rode uma regularização ridge com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o R2 na base de testes. \n",
    "# Qual o melhor modelo?\n",
    "\n",
    "# Listar os valores de alpha a serem utilizados\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Armazenar os R-Quadrados para cada valor de alpha\n",
    "r2_rid_list = [] \n",
    "\n",
    "# Definir o modelo\n",
    "modelo = smf.ols('renda ~ tempo_emprego', data = renda)\n",
    "\n",
    "# Definir uma função para calcular os R-Quadrados \n",
    "def calcular_r2(y_test, y_pred):\n",
    "    ss_res = np.sum((y_test - y_pred)**2)\n",
    "    ss_tot = np.sum((y_test - np.mean(y_test))**2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "\n",
    "# Iterar sobre os valores de alpha\n",
    "for alpha in alphas:\n",
    "    # Ajustar o modelo utilizando a regularização Ridge (L2 >> L1_wt=0)\n",
    "    reg_rid = modelo.fit_regularized(method='elastic_net', \n",
    "                                     refit=True, \n",
    "                                     L1_wt=0, \n",
    "                                     alpha=alpha)\n",
    "    # Fazer previsões\n",
    "    y_pred = reg_rid.predict(X_test)\n",
    "    \n",
    "    # Calcular o R-Quadrado e adicionar a lista\n",
    "    r2_rid = calcular_r2(y_test, y_pred)\n",
    "    r2_rid_list.append(r2_rid)\n",
    "\n",
    "# Retornar a lista de R-Quadrados\n",
    "print(alphas)\n",
    "print(r2_rid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESPOSTA\n",
    "Os modelos não apresentaram diferenças significativas em termos de desempenho. O valor mais alto para o R-Quadrado foi obtido com alpha = 0.01, com R-Quadrado de aproximadamente 0.1613, enquanto o valor mais baixo foi com alpha = 0.1, com R-Quadrado de 0.1608. A diferença máxima entre os dois melhores modelos (com alpha = 0.005 e alpha = 0.01) foi de apenas 0.0018%, o que pode indicar que a Regularização Ridge não trouxe melhorias substanciais sobre o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Alpha     Ridge     Lasso\n",
      "0  0.000  0.161313  0.160833\n",
      "1  0.001  0.161317  0.160833\n",
      "2  0.005  0.161334  0.160833\n",
      "3  0.010  0.161348  0.160833\n",
      "4  0.050  0.161266  0.160833\n",
      "5  0.100  0.160833  0.160833\n"
     ]
    }
   ],
   "source": [
    "# 03 - Faça o mesmo que no passo 2, com uma regressão LASSO. Qual método chega a um melhor resultado?\n",
    "\n",
    "# Armazenar os resultados do R² para Lasso\n",
    "r2_las_list = []\n",
    "\n",
    "# Iterar os valores de alpha\n",
    "for alpha in alphas:\n",
    "    # Ajustar o modelo utilizando a regularização Lasso (L1 >> L1_wt=1)\n",
    "    reg_las = modelo.fit_regularized(method='elastic_net', \n",
    "                                       L1_wt=1, \n",
    "                                       refit=True,\n",
    "                                       alpha=alpha)\n",
    "    # Fazer previsões\n",
    "    y_pred_las = reg_las.predict(X_test)\n",
    "    \n",
    "    # Calcular o R-Quadrado e adicionar a lista\n",
    "    r2_las = calcular_r2(y_test, y_pred)\n",
    "    r2_las_list.append(r2_las)\n",
    "\n",
    "# Retornar tabela de R-Quadrados\n",
    "r2 =pd.DataFrame({\n",
    "    'Alpha': alphas,\n",
    "    'Ridge': r2_rid_list,\n",
    "    'Lasso': r2_las_list})\n",
    "\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resposta: \n",
    "Após a regularização L2 os modelos não apresentaram nenhuma alteração significativa. Mesmo com a alteração do alpha, o R-Quadrado dos modelos permaneceu inalterado. Observa-se que o valor do R-Quadrado è o memso valor do menor R-Quadrado da regularização L1. Podemos concluir que a regularização Ridge apresentou maior efeito porém o fenonomeno observado não é significativo para justificar a escolha de um modelo sobre o outro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  tempo_emprego                  with p-value 0.0\n",
      "Add  sexo_M                         with p-value 0.0\n",
      "Add  tipo_renda_Empresário          with p-value 1.75299e-07\n",
      "Add  idade                          with p-value 1.9605e-07\n",
      "Add  educacao_Superior completo     with p-value 3.07164e-06\n",
      "Add  qt_pessoas_residencia          with p-value 0.00747762\n",
      "Add  posse_de_imovel                with p-value 0.0138522\n",
      "resulting features:\n",
      "['tempo_emprego', 'sexo_M', 'tipo_renda_Empresário', 'idade', 'educacao_Superior completo', 'qt_pessoas_residencia', 'posse_de_imovel']\n"
     ]
    }
   ],
   "source": [
    "# 04 - Rode um modelo stepwise. Avalie o R-Quadrado na base de testes. Qual o melhor resultado?\n",
    "\n",
    "\n",
    "# Garantir que todas as colunas de X e y sejam do tipo float\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Definir a função de seleção stepwise\n",
    "def stepwise_selection(X_test, y_test,\n",
    "                       initial_list=[],\n",
    "                       threshold_in=0.05,\n",
    "                       threshold_out=0.05,\n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection\n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features\n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed = False\n",
    "        # forward step\n",
    "        # começamos pela lista de variaveis excluidas\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded, dtype=np.float64)\n",
    "        # para que toda variavel excluida vá sendo incluida e o p-value armazenado\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        # vai retirando as váriaveis menos significantes\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max()  # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "# Executar a seleção stepwise\n",
    "variaveis = stepwise_selection(X_test, y_test)\n",
    "\n",
    "print('resulting features:')\n",
    "print(variaveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>renda</td>      <th>  R-squared:         </th>  <td>   0.256</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.255</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   304.8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 25 Sep 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:42:11</td>     <th>  Log-Likelihood:    </th> <td>-1.2879e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 12427</td>      <th>  AIC:               </th>  <td>2.576e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 12413</td>      <th>  BIC:               </th>  <td>2.577e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>-3947.2300</td> <td>  854.037</td> <td>   -4.622</td> <td> 0.000</td> <td>-5621.276</td> <td>-2273.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sexo[T.M]</th>                       <td> 6087.0647</td> <td>  146.321</td> <td>   41.601</td> <td> 0.000</td> <td> 5800.253</td> <td> 6373.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda[T.Bolsista]</th>          <td>-1321.2957</td> <td> 2563.054</td> <td>   -0.516</td> <td> 0.606</td> <td>-6345.279</td> <td> 3702.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda[T.Empresário]</th>        <td>  816.2292</td> <td>  158.330</td> <td>    5.155</td> <td> 0.000</td> <td>  505.878</td> <td> 1126.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda[T.Pensionista]</th>       <td>-2825.5973</td> <td> 2561.409</td> <td>   -1.103</td> <td> 0.270</td> <td>-7846.356</td> <td> 2195.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda[T.Servidor público]</th>  <td>  135.3801</td> <td>  235.912</td> <td>    0.574</td> <td> 0.566</td> <td> -327.044</td> <td>  597.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao[T.Pós graduação]</th>       <td> 1068.2331</td> <td> 1686.541</td> <td>    0.633</td> <td> 0.526</td> <td>-2237.648</td> <td> 4374.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao[T.Secundário]</th>          <td>  595.8283</td> <td>  762.481</td> <td>    0.781</td> <td> 0.435</td> <td> -898.752</td> <td> 2090.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao[T.Superior completo]</th>   <td> 1214.2466</td> <td>  765.604</td> <td>    1.586</td> <td> 0.113</td> <td> -286.456</td> <td> 2714.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao[T.Superior incompleto]</th> <td>  190.4879</td> <td>  824.180</td> <td>    0.231</td> <td> 0.817</td> <td>-1425.032</td> <td> 1806.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>posse_de_imovel[T.True]</th>         <td>  353.6617</td> <td>  145.637</td> <td>    2.428</td> <td> 0.015</td> <td>   68.190</td> <td>  639.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo_emprego</th>                   <td>  554.1097</td> <td>   11.014</td> <td>   50.308</td> <td> 0.000</td> <td>  532.520</td> <td>  575.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>idade</th>                           <td>   45.4058</td> <td>    8.200</td> <td>    5.538</td> <td> 0.000</td> <td>   29.333</td> <td>   61.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qt_pessoas_residencia</th>           <td>  191.5689</td> <td>   76.195</td> <td>    2.514</td> <td> 0.012</td> <td>   42.215</td> <td>  340.923</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17579.310</td> <th>  Durbin-Watson:     </th>  <td>   2.035</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>9929026.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 8.133</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>140.518</td>  <th>  Cond. No.          </th>  <td>1.59e+03</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.59e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &      renda       & \\textbf{  R-squared:         } &      0.256   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &      0.255   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &      304.8   \\\\\n",
       "\\textbf{Date:}                           & Wed, 25 Sep 2024 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n",
       "\\textbf{Time:}                           &     19:42:11     & \\textbf{  Log-Likelihood:    } & -1.2879e+05  \\\\\n",
       "\\textbf{No. Observations:}               &       12427      & \\textbf{  AIC:               } &  2.576e+05   \\\\\n",
       "\\textbf{Df Residuals:}                   &       12413      & \\textbf{  BIC:               } &  2.577e+05   \\\\\n",
       "\\textbf{Df Model:}                       &          14      & \\textbf{                     } &              \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &              \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &   -3947.2300  &      854.037     &    -4.622  &         0.000        &    -5621.276    &    -2273.184     \\\\\n",
       "\\textbf{sexo[T.M]}                       &    6087.0647  &      146.321     &    41.601  &         0.000        &     5800.253    &     6373.876     \\\\\n",
       "\\textbf{tipo\\_renda[T.Bolsista]}         &   -1321.2957  &     2563.054     &    -0.516  &         0.606        &    -6345.279    &     3702.688     \\\\\n",
       "\\textbf{tipo\\_renda[T.Empresário]}       &     816.2292  &      158.330     &     5.155  &         0.000        &      505.878    &     1126.580     \\\\\n",
       "\\textbf{tipo\\_renda[T.Pensionista]}      &   -2825.5973  &     2561.409     &    -1.103  &         0.270        &    -7846.356    &     2195.161     \\\\\n",
       "\\textbf{tipo\\_renda[T.Servidor público]} &     135.3801  &      235.912     &     0.574  &         0.566        &     -327.044    &      597.804     \\\\\n",
       "\\textbf{educacao[T.Pós graduação]}       &    1068.2331  &     1686.541     &     0.633  &         0.526        &    -2237.648    &     4374.114     \\\\\n",
       "\\textbf{educacao[T.Secundário]}          &     595.8283  &      762.481     &     0.781  &         0.435        &     -898.752    &     2090.409     \\\\\n",
       "\\textbf{educacao[T.Superior completo]}   &    1214.2466  &      765.604     &     1.586  &         0.113        &     -286.456    &     2714.950     \\\\\n",
       "\\textbf{educacao[T.Superior incompleto]} &     190.4879  &      824.180     &     0.231  &         0.817        &    -1425.032    &     1806.008     \\\\\n",
       "\\textbf{posse\\_de\\_imovel[T.True]}       &     353.6617  &      145.637     &     2.428  &         0.015        &       68.190    &      639.133     \\\\\n",
       "\\textbf{tempo\\_emprego}                  &     554.1097  &       11.014     &    50.308  &         0.000        &      532.520    &      575.700     \\\\\n",
       "\\textbf{idade}                           &      45.4058  &        8.200     &     5.538  &         0.000        &       29.333    &       61.478     \\\\\n",
       "\\textbf{qt\\_pessoas\\_residencia}         &     191.5689  &       76.195     &     2.514  &         0.012        &       42.215    &      340.923     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 17579.310 & \\textbf{  Durbin-Watson:     } &      2.035   \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 9929026.258  \\\\\n",
       "\\textbf{Skew:}          &    8.133  & \\textbf{  Prob(JB):          } &       0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &  140.518  & \\textbf{  Cond. No.          } &   1.59e+03   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.59e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  renda   R-squared:                       0.256\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     304.8\n",
       "Date:                Wed, 25 Sep 2024   Prob (F-statistic):               0.00\n",
       "Time:                        19:42:11   Log-Likelihood:            -1.2879e+05\n",
       "No. Observations:               12427   AIC:                         2.576e+05\n",
       "Df Residuals:                   12413   BIC:                         2.577e+05\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                       -3947.2300    854.037     -4.622      0.000   -5621.276   -2273.184\n",
       "sexo[T.M]                        6087.0647    146.321     41.601      0.000    5800.253    6373.876\n",
       "tipo_renda[T.Bolsista]          -1321.2957   2563.054     -0.516      0.606   -6345.279    3702.688\n",
       "tipo_renda[T.Empresário]          816.2292    158.330      5.155      0.000     505.878    1126.580\n",
       "tipo_renda[T.Pensionista]       -2825.5973   2561.409     -1.103      0.270   -7846.356    2195.161\n",
       "tipo_renda[T.Servidor público]    135.3801    235.912      0.574      0.566    -327.044     597.804\n",
       "educacao[T.Pós graduação]        1068.2331   1686.541      0.633      0.526   -2237.648    4374.114\n",
       "educacao[T.Secundário]            595.8283    762.481      0.781      0.435    -898.752    2090.409\n",
       "educacao[T.Superior completo]    1214.2466    765.604      1.586      0.113    -286.456    2714.950\n",
       "educacao[T.Superior incompleto]   190.4879    824.180      0.231      0.817   -1425.032    1806.008\n",
       "posse_de_imovel[T.True]           353.6617    145.637      2.428      0.015      68.190     639.133\n",
       "tempo_emprego                     554.1097     11.014     50.308      0.000     532.520     575.700\n",
       "idade                              45.4058      8.200      5.538      0.000      29.333      61.478\n",
       "qt_pessoas_residencia             191.5689     76.195      2.514      0.012      42.215     340.923\n",
       "==============================================================================\n",
       "Omnibus:                    17579.310   Durbin-Watson:                   2.035\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          9929026.258\n",
       "Skew:                           8.133   Prob(JB):                         0.00\n",
       "Kurtosis:                     140.518   Cond. No.                     1.59e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.59e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_stw = 'renda ~ tempo_emprego + sexo + tipo_renda + idade + educacao + qt_pessoas_residencia + posse_de_imovel'\n",
    "mod = smf.ols(mod_stw, data = renda)\n",
    "\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05 - Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resposta:\n",
    "\n",
    "Todas as variáveis resultantes do Stepwise apresentam p-value menor que 0.05, isso sugere que o conjunto de variáveis selecionadas pelo stepwise é relevante para o modelo, pois contribuem significativamente para a explicação da variável dependente 'remda'. Isso sugere que o conjunto de variáveis selecionadas pelo stepwise é relevante para o modelo. Ao testar o modelo com as variáveis retornada no Stepwise observa-se que o modelo é capaz de explicar 25.6% da variabilidade da variável dependente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>np.log(renda + 1)</td> <th>  R-squared:         </th> <td>   0.356</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.355</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   527.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 25 Sep 2024</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:48:11</td>      <th>  Log-Likelihood:    </th> <td> -13579.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 12427</td>       <th>  AIC:               </th> <td>2.719e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 12413</td>       <th>  BIC:               </th> <td>2.729e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>    7.0986</td> <td>    0.080</td> <td>   88.331</td> <td> 0.000</td> <td>    6.941</td> <td>    7.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sexo[T.M]</th>                       <td>    0.7997</td> <td>    0.014</td> <td>   58.083</td> <td> 0.000</td> <td>    0.773</td> <td>    0.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda[T.Bolsista]</th>          <td>    0.1961</td> <td>    0.241</td> <td>    0.813</td> <td> 0.416</td> <td>   -0.277</td> <td>    0.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda[T.Empresário]</th>        <td>    0.1536</td> <td>    0.015</td> <td>   10.307</td> <td> 0.000</td> <td>    0.124</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda[T.Pensionista]</th>       <td>   -0.3165</td> <td>    0.241</td> <td>   -1.313</td> <td> 0.189</td> <td>   -0.789</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda[T.Servidor público]</th>  <td>    0.0587</td> <td>    0.022</td> <td>    2.646</td> <td> 0.008</td> <td>    0.015</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao[T.Pós graduação]</th>       <td>    0.1143</td> <td>    0.159</td> <td>    0.721</td> <td> 0.471</td> <td>   -0.197</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao[T.Secundário]</th>          <td>   -0.0149</td> <td>    0.072</td> <td>   -0.207</td> <td> 0.836</td> <td>   -0.156</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao[T.Superior completo]</th>   <td>    0.0965</td> <td>    0.072</td> <td>    1.339</td> <td> 0.180</td> <td>   -0.045</td> <td>    0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao[T.Superior incompleto]</th> <td>   -0.0460</td> <td>    0.078</td> <td>   -0.593</td> <td> 0.553</td> <td>   -0.198</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>posse_de_imovel[T.True]</th>         <td>    0.0833</td> <td>    0.014</td> <td>    6.077</td> <td> 0.000</td> <td>    0.056</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo_emprego</th>                   <td>    0.0615</td> <td>    0.001</td> <td>   59.384</td> <td> 0.000</td> <td>    0.060</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>idade</th>                           <td>    0.0054</td> <td>    0.001</td> <td>    7.042</td> <td> 0.000</td> <td>    0.004</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qt_pessoas_residencia</th>           <td>    0.0221</td> <td>    0.007</td> <td>    3.084</td> <td> 0.002</td> <td>    0.008</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.707</td> <th>  Durbin-Watson:     </th> <td>   2.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.702</td> <th>  Jarque-Bera (JB):  </th> <td>   0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.017</td> <th>  Prob(JB):          </th> <td>   0.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.012</td> <th>  Cond. No.          </th> <td>1.59e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.59e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  & np.log(renda + 1) & \\textbf{  R-squared:         } &     0.356   \\\\\n",
       "\\textbf{Model:}                          &        OLS        & \\textbf{  Adj. R-squared:    } &     0.355   \\\\\n",
       "\\textbf{Method:}                         &   Least Squares   & \\textbf{  F-statistic:       } &     527.6   \\\\\n",
       "\\textbf{Date:}                           &  Wed, 25 Sep 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                           &      19:48:11     & \\textbf{  Log-Likelihood:    } &   -13579.   \\\\\n",
       "\\textbf{No. Observations:}               &        12427      & \\textbf{  AIC:               } & 2.719e+04   \\\\\n",
       "\\textbf{Df Residuals:}                   &        12413      & \\textbf{  BIC:               } & 2.729e+04   \\\\\n",
       "\\textbf{Df Model:}                       &           13      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &     nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &       7.0986  &        0.080     &    88.331  &         0.000        &        6.941    &        7.256     \\\\\n",
       "\\textbf{sexo[T.M]}                       &       0.7997  &        0.014     &    58.083  &         0.000        &        0.773    &        0.827     \\\\\n",
       "\\textbf{tipo\\_renda[T.Bolsista]}         &       0.1961  &        0.241     &     0.813  &         0.416        &       -0.277    &        0.669     \\\\\n",
       "\\textbf{tipo\\_renda[T.Empresário]}       &       0.1536  &        0.015     &    10.307  &         0.000        &        0.124    &        0.183     \\\\\n",
       "\\textbf{tipo\\_renda[T.Pensionista]}      &      -0.3165  &        0.241     &    -1.313  &         0.189        &       -0.789    &        0.156     \\\\\n",
       "\\textbf{tipo\\_renda[T.Servidor público]} &       0.0587  &        0.022     &     2.646  &         0.008        &        0.015    &        0.102     \\\\\n",
       "\\textbf{educacao[T.Pós graduação]}       &       0.1143  &        0.159     &     0.721  &         0.471        &       -0.197    &        0.425     \\\\\n",
       "\\textbf{educacao[T.Secundário]}          &      -0.0149  &        0.072     &    -0.207  &         0.836        &       -0.156    &        0.126     \\\\\n",
       "\\textbf{educacao[T.Superior completo]}   &       0.0965  &        0.072     &     1.339  &         0.180        &       -0.045    &        0.238     \\\\\n",
       "\\textbf{educacao[T.Superior incompleto]} &      -0.0460  &        0.078     &    -0.593  &         0.553        &       -0.198    &        0.106     \\\\\n",
       "\\textbf{posse\\_de\\_imovel[T.True]}       &       0.0833  &        0.014     &     6.077  &         0.000        &        0.056    &        0.110     \\\\\n",
       "\\textbf{tempo\\_emprego}                  &       0.0615  &        0.001     &    59.384  &         0.000        &        0.060    &        0.064     \\\\\n",
       "\\textbf{idade}                           &       0.0054  &        0.001     &     7.042  &         0.000        &        0.004    &        0.007     \\\\\n",
       "\\textbf{qt\\_pessoas\\_residencia}         &       0.0221  &        0.007     &     3.084  &         0.002        &        0.008    &        0.036     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.707 & \\textbf{  Durbin-Watson:     } &    2.023  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.702 & \\textbf{  Jarque-Bera (JB):  } &    0.688  \\\\\n",
       "\\textbf{Skew:}          &  0.017 & \\textbf{  Prob(JB):          } &    0.709  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.012 & \\textbf{  Cond. No.          } & 1.59e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.59e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      np.log(renda + 1)   R-squared:                       0.356\n",
       "Model:                            OLS   Adj. R-squared:                  0.355\n",
       "Method:                 Least Squares   F-statistic:                     527.6\n",
       "Date:                Wed, 25 Sep 2024   Prob (F-statistic):               0.00\n",
       "Time:                        19:48:11   Log-Likelihood:                -13579.\n",
       "No. Observations:               12427   AIC:                         2.719e+04\n",
       "Df Residuals:                   12413   BIC:                         2.729e+04\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                           7.0986      0.080     88.331      0.000       6.941       7.256\n",
       "sexo[T.M]                           0.7997      0.014     58.083      0.000       0.773       0.827\n",
       "tipo_renda[T.Bolsista]              0.1961      0.241      0.813      0.416      -0.277       0.669\n",
       "tipo_renda[T.Empresário]            0.1536      0.015     10.307      0.000       0.124       0.183\n",
       "tipo_renda[T.Pensionista]          -0.3165      0.241     -1.313      0.189      -0.789       0.156\n",
       "tipo_renda[T.Servidor público]      0.0587      0.022      2.646      0.008       0.015       0.102\n",
       "educacao[T.Pós graduação]           0.1143      0.159      0.721      0.471      -0.197       0.425\n",
       "educacao[T.Secundário]             -0.0149      0.072     -0.207      0.836      -0.156       0.126\n",
       "educacao[T.Superior completo]       0.0965      0.072      1.339      0.180      -0.045       0.238\n",
       "educacao[T.Superior incompleto]    -0.0460      0.078     -0.593      0.553      -0.198       0.106\n",
       "posse_de_imovel[T.True]             0.0833      0.014      6.077      0.000       0.056       0.110\n",
       "tempo_emprego                       0.0615      0.001     59.384      0.000       0.060       0.064\n",
       "idade                               0.0054      0.001      7.042      0.000       0.004       0.007\n",
       "qt_pessoas_residencia               0.0221      0.007      3.084      0.002       0.008       0.036\n",
       "==============================================================================\n",
       "Omnibus:                        0.707   Durbin-Watson:                   2.023\n",
       "Prob(Omnibus):                  0.702   Jarque-Bera (JB):                0.688\n",
       "Skew:                           0.017   Prob(JB):                        0.709\n",
       "Kurtosis:                       3.012   Cond. No.                     1.59e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.59e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 06 - Partindo dos modelos que você ajustou, tente melhorar o R-Quadrado na base de testes. \n",
    "# Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "\n",
    "modelo = 'np.log(renda + 1) ~ tempo_emprego + sexo + tipo_renda + idade + educacao + qt_pessoas_residencia + posse_de_imovel'\n",
    "mod = smf.ols(modelo, data = renda).fit()\n",
    "\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resposta\n",
    "A transformação logarítmica da variável dependente resultou em um aumento substancial no desempenho do modelo, conforme medido pelo R², passando de 25% para 35.6%. O R² Ajustado próximo ao R² não ajustado indica que o modelo é robusto, sem superajuste, e que a escolha das variáveis foi adequada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O valor de ccp_alpha que minimiza o MSE no conjunto de teste é: 6710.970531484243\n"
     ]
    }
   ],
   "source": [
    "# 07 - Ajuste uma árvore de regressão e veja se consegue um R-Quadrado melhor com ela.\n",
    "# Gerar árvore\n",
    "regr = DecisionTreeRegressor(max_depth=8)\n",
    "\n",
    "# Treinar árvore\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões sobre a base de treinamento\n",
    "y_train_pred = regr.predict(X_train)\n",
    "\n",
    "# Calcular os CCPS-Alphas\n",
    "path = regr.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "# Treinar árvores com os caminhos obtidos\n",
    "clfs = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "\n",
    "# Calcular MSE das árvores\n",
    "train_scores = [mean_squared_error(y_train , clf.predict(X_train)) for clf in clfs]\n",
    "test_scores = [mean_squared_error(y_test , clf.predict(X_test)) for clf in clfs]\n",
    "\n",
    "# Plotar gráfico com os resultados\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Configurar gráfico\n",
    "ax.set_xlabel(\"CCP Alpha\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"MSE x CCP Alpha do conjunto de dados de treino e teste\")\n",
    "\n",
    "# Plotar os MSEs para os dados de treinamento\n",
    "ax.plot(ccp_alphas[:-1], train_scores[:-1], marker='o', label=\"Treinamento\", drawstyle=\"steps-post\")\n",
    "\n",
    "# Plotar os MSEs para os dados de teste\n",
    "ax.plot(ccp_alphas[:-1], test_scores[:-1], marker='o', label=\"Teste\", drawstyle=\"steps-post\")\n",
    "\n",
    "# Adicionar uma linha vertical no ponto de mínimo do MSE do conjunto de teste\n",
    "min_mse_index = np.argmin(test_scores[:-1])\n",
    "best_ccp_alpha = ccp_alphas[min_mse_index]\n",
    "ax.axvline(x=best_ccp_alpha, color='r', linestyle='--', label=f'alpha min = {best_ccp_alpha:.4f}')\n",
    "\n",
    "# Adicionar legenda\n",
    "ax.legend()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()\n",
    "\n",
    "print(f'O valor de ccp_alpha que minimiza o MSE no conjunto de teste é: {best_ccp_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidade: 24\n",
      "R-quadrado na base de testes: 0.43\n",
      "MSE na base de testes: 46728522.11\n"
     ]
    }
   ],
   "source": [
    "# Calcular os coeficientes de árvore com MSE mínimo\n",
    "arv_fin = DecisionTreeRegressor(random_state=0, ccp_alpha=best_ccp_alpha)\n",
    "arv_fin.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Profundidade: {arv_fin.tree_.max_depth}\")\n",
    "print(f\"R-quadrado na base de testes: {arv_fin.score(X_test, y_test):.2f}\")\n",
    "print(f\"MSE na base de testes: {mean_squared_error(y_test, arv_fin.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resposta:\n",
    "\n",
    "Através da árvore de regressão com poda baseada no parâmetro ccp_alpha, o modelo conseguiu explicar 43% da variabilidade da variável dependente, conforme indicado pelo R-Quadrado de 0.43 no conjunto de teste. Apesar de um desempenho moderado, o MSE (Erro Quadrático Médio) na base de testes foi relativamente alto o que indica que o modelo ainda tem espaço para melhorias em termos de precisão.\n",
    "\n",
    "Além disso, a profundidade da árvore foi de 24, o que sugere que o modelo é relativamente complexo. Modelos com alta profundidade podem ser propensos a overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
